{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gary1345aa\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import datasets\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cut_programs = np.load('cut_Programs.npy')\n",
    "cut_Question = np.load('cut_Questions.npy')\n",
    "voc_dict = np.load('voc_dict.npy')\n",
    "example_doc = np.load('example_doc.npy')\n",
    "w2v_doc = np.load('w2v_doc.npy')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_doc = []\n",
    "\n",
    "for program in cut_programs:\n",
    "    for lines in program:\n",
    "        for line in lines:\n",
    "            example_line = ''\n",
    "            for w in line:\n",
    "                if w in voc_dict:\n",
    "                    example_line += w+' '    \n",
    "            example_doc.append(example_line)\n",
    "            \n",
    "for qset in range(len(cut_Question)):\n",
    "    for QA in range(len(cut_Question[qset])):\n",
    "        if QA == 0:\n",
    "            for line in cut_Question[qset][QA]:\n",
    "                example_line = ''\n",
    "                for word in line:\n",
    "                    example_line += word+' '\n",
    "                example_doc.append(example_line)\n",
    "        else:\n",
    "            example_line = ''\n",
    "            for word in cut_Question[qset][QA]:\n",
    "                example_line += word+' '\n",
    "            example_doc.append(example_line)\n",
    "\n",
    "np.save('example_doc', example_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_doc = []\n",
    "\n",
    "for program in cut_programs:\n",
    "    for lines in program:\n",
    "        for line in lines:  \n",
    "            tem = []\n",
    "            for w in line:\n",
    "                if w in voc_dict:\n",
    "                    tem.append(w)\n",
    "            w2v_doc.append(tem)\n",
    "            \n",
    "            \n",
    "for qset in range(len(cut_Question)):\n",
    "    for QA in range(len(cut_Question[qset])):\n",
    "        if QA == 0:\n",
    "            for line in cut_Question[qset][QA]:\n",
    "                tem = []\n",
    "                for word in line:\n",
    "                    tem.append(word)\n",
    "                w2v_doc.append(tem)\n",
    "        else:\n",
    "            tem = []\n",
    "            for word in cut_Question[qset][QA]:\n",
    "                tem.append(word)\n",
    "            w2v_doc.append(tem)\n",
    "\n",
    "np.save('w2v_doc', w2v_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "\n",
    "hashvec = HashingVectorizer(n_features=2**6)\n",
    "count = CountVectorizer(ngram_range=(1, 1))\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1))\n",
    "count.fit(example_doc)\n",
    "tfidf.fit(example_doc)\n",
    "\n",
    "idf = tfidf.vocabulary_\n",
    "BoW = count.vocabulary_\n",
    "\n",
    "joblib.dump(count, 'BoW.pkl')\n",
    "joblib.dump(tfidf, 'tfidf.pkl')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "if '輕而易舉' in idf :\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2V = word2vec.Word2Vec(sentences=w2v_doc, size=256, window=5, min_count=1, workers=12)\n",
    "W2V.save('W2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
